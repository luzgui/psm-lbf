# experiment config
exp_name: fcul1

pol_type: agent_pol #shared_pol shared policy or each agent will have its own policy

algorithm:
  # name: PPO #CentralizedCritic ....
  name: CentralizedCritic
  config: 'ppo_config.yaml'
environment_cls: 'FlexEnv'

#tune config
mode: max
metric: episode_reward_mean

# Run config
verbose: 0

#trainable config
n_iters: 1000
checkpoint_freq: 200

#resources
num_cpu: 3.0
num_gpu: 0.0
cpu_factor: 10

#resources
# b={'CPU':3,'GPU':0.1}
# resources=tune.PlacementGroupFactory([b]*10)
# config.num_rollout_workers=10

# CPU: 1.0}] + [{'CPU': 1.0}] * 6)

#resources FCUL
# b={'CPU':3,'GPU':0.1}
# resources=tune.PlacementGroupFactory([b]*10)
# config.num_rollout_workers=10
